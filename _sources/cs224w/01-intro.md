## 01-introduction

### 图机器学习

什么是图？

图是描述和分析实体及其关系的一种通用语言



各种类型的图：

- 事件图、计算机网络、疾病发展路径、食物网、粒子网、地铁交通网、社交网络、经济网络、通信网络、引用网络、互联网、神经网络、知识图谱、监管网络、场景图、代码图、分子、3D形状



那么我们该如何利用关系结构进行更好的预测？

- 复杂领域具有丰富的关系结构，可以表示为关系图
- 通过对关系的显式建模来进行更好的预测!



如今的深度学习工具箱是根据简单的序列/网格来进行设计的：

- images
- text\speech

但是不是一切事物都可以被表征为序列或者网格，我们该如何才能开发出适用范围更广的神经网络呢？

- 图即是深度学习新的前沿
- 图让万物相连



为什么图深度学习很难？

- 具有不确定的尺寸
- 具有复杂的拓扑结构（不像网格具有空间局部性）
- 没有固定的结点顺序或参考结点
- 通常是动态的并具有多模态特征



图神经网络

- 输入为：network

- 输出为：结点标签、新连接、生成的图和子图

- 每个结点定义为一个计算图
  - 每个计算图中的边可以被认为是转换/聚合函数

​	因此，结点通过神经网络聚合来自其邻居的信息，即每个结点根据其邻居定义一个计算图。



表示学习

**表示学习，这一页没看懂**

- 将结点映射到d维的嵌入，使得网络中相似的结点的嵌入更接近



因此，我们将探索图数据的机器学习和表示学习：

- 传统方法: Graphlets, Graph Kernels
- 结点嵌入的方法: DeepWalk, Node2Vec
- 图神经网络: GCN, GraphSAGE, GAT, Theory of GNNs
- 知识图谱与推理: TransE, BetaE
- 深度图聚合模型: GraphRNN
- 前沿应用：Applications to Biomedicine, Science, Technology



## 图机器学习的应用

#### 不同类型的任务

- graph-level prediction, graph generation
- node level
- community (subgraph level)
- edge-level



#### 经典的图机器学习任务：

- 结点分类：预测一个结点的属性
  - 对在线的用户或条目进行分类
- 连接预测：预测两个结点之间是否存在连接丢失
  - 知识图谱补全
- 图分类：对不同的图进行分类
  - 分子属性预测
- 聚类：检测一些结点是否可形成子图
  - 社交圈检测
- 其他：
  - 图生成：药物挖掘
  - 图演化：物理模拟

这些任务都会导致广泛的应用



#### Node-level 图机器学习任务

- 蛋白质折叠

- 蛋白质折叠问题

- AlphaFold：

  - 核心思想：空间图
  - 结点：蛋白质序列中的氨基酸
  - 边：氨基酸（残基）之间的接近度

  

#### Edge-level 图机器学习任务

1. 推荐系统

- 用户与物品进行交互
  - 看电影、购买商品、听音乐
  - 结点：用户和物品
  - 边：用于-物品之间的交互
- 目的：推荐用户可能喜欢的物品

2. 药物副作用

   许多患者服用药物来治疗复杂或并存的疾病

   - 任务：给出一对药物，来预测其副作用
   - 结点：药物与蛋白质
   - 边：其间的关系

#### Subgraph-level 图机器学习任务

交通预测，将道路网看作是图结构

- 结点：路段
- 边：路段之间的连通性
- 预测：到达时间



#### Graph-level 图机器学习任务

1. 药物发现

抗生素可以看作是小分子图

- 结点：原子
- 边：化学键

图神经网络模型，从候选池中预测有潜力的分子

2. 分子生成/优化

- 生成高药似值的分子
- 优化现有分子以获得理想的属性

3. 物理模拟

   将物理模拟看作是图：

   - 结点：粒子
   - 边：粒子间的相互作用

一个图演化网络

- 目的：预测图将如何演化

- 如 deepmind天气预测

#### 图表示的选择

图的组成：

- 对象：结点、顶点（$N$）
- 交互：连接、边 （$E$）
- 系统：网络、图 （$G(N, E)$）



选择合适的表示：

- 如果您将相互合作的个人联系起来，您将探索一个professional network
- 如果您连接那些有性关系的人，您将探索sexual network
- 如果您连接相互引用的科学论文，您将研究citation network

如果您将所有论文的标题中的同一个词连接起来，您将探索什么？

- 依旧是一个网络



如何定义一个图：

1. 如何构建一个图？
   - 什么是结点？
   - 什么是边？
2. 给定领域/问题，适当的网络表示决定了我们成功使用网络的能力：
   - 在某些情况下，存在唯一、明确的表示
   - 在其他情况下，表示不是唯一的
   - 分配连接的方式将决定您可以研究问题的性质

有向图和无向图

- 无向图（Undirected）
  - 连接：无向的（对称的，相反的）
  - 如同事关系、友谊关系
- 有向图（Directed）
  - 连接：有向的（弧）
  - 来电、推特的关注

异质图（Heterogeneous）

- 异质图可以表示为$G=(V,E,R,T)$
- 结点的类型 $v_i \in V$
- 边的关系类型 $(v_i,r,v_j)\in E$
- 结点类型 $T(v_i)$
- 关系类型 $r\in R$



异质图举例

1. 医疗知识图谱
   - 结点：偏头痛
   - 边：氟维司群、治疗、乳腺肿瘤
   - 结点类型：蛋白质
   - 关系类型：导致的原因
2. 学术图
   - 结点：ICML
   - 边：GraphSAGE、NeurIPS
   - 结点类型：作者
   - 关系类型：出版年

结点的度

1. 无向图：
   - 结点的度 $k_i$：跟结点 $i$ 相连的边的数量
   - 平均度：$\bar k=<k>=\frac{1}{N}\sum_{i=1}^{N}k_i=\frac{2E}{N}$
2. 有向图：有向图中包含入度和出度，一个结点的度是出度和入度之和
   - $\bar k =\frac{E}{N}$
   - $\bar k^{in} = \bar k^{out}$



二分图

1. 二分图：是一个图，其结点可以分为两个不相交的集合 $U$ 和$ V$，这样每条链接都将 $U$ 中的一个结点连接到 $V$ 中的一个结点；即 $U$ 和 $V$ 是**独立的集合**
2. 举例
   - 作者-论文
   - 演员-电影
   - 观众-电影
   - 食谱-配料
3. “折叠”网络
   - 作者合作网络
   - 电影联合评级网络

图表示：邻接矩阵A

- $A_{ij}=1$ 表示存在结点 $i$ 到结点 $j$ 之间的连接
- $A_{ij}=0$ 表示不存在结点 $i$ 到结点 $j$ 之间的连接
- 注意：有向图的邻接矩阵不是对称的
- 邻接矩阵是稀疏的



网络是稀疏图

- 大多数真实世界的网络都是稀疏的，$E << E_{max}\ (or\ k << N - 1)$
- 这就导致了邻接矩阵包含有大量的0



结点和边的属性包括：

- 权重（如通信频率）
- 排序（最好的朋友，第二好的朋友）
- 类型（朋友，亲戚，同事）
- 标记（朋友-敌人，信任-不信任）
- 属性取决于图中其余部分的结构：如一般朋友的数量



更多类型的图

1. 无权无向图（Unweighted， Undirected）
   - $A_{ii}=0$
   - $A_{ij}=A_{ji}$ 对称的
   - $E=\frac{1}{2}\sum_{i,j=1}^{N}A_{ij}$
   - $\bar k = \frac{2E}{N}\bar k = \frac{2E}{N}$
   - 友谊、超链接
2. 有权无向图（Weighted, Undirected）
   - $A_{ii}=0$
   - $A_{ij} = A_{ji}$ 对称的
   - $E=\frac{1}{2}\sum_{i,j=1}^{N}nonzero(A_{ij})$
   - $\bar k = \frac{2E}{N}\bar k = \frac{2E}{N}$
   - 协作关系、互联网、路段
3. 自循环无向图（self-edge/self-loop，undirected）
   - $A_{ii} \neq 0$
   - $A_{ij} = A{ji}$ 对称的
   - $E=\frac{1}{2}\sum_{i,j=1, i\neq j}^{N}A_{ij}+\sum_{i=1}^{N}A_{ii}$
   - 蛋白质
4. Multigraph （无向图）
   - $A_{ii} = 0$
   - $A_{ij} = A_{ji}$ 对称的
   - $E=\frac{1}{2}\sum_{i,j=1}^{N}nonzero(A_{ij})$
   - $\bar k = \frac{2E}{N}\bar k = \frac{2E}{N}$
   - 通信、协作



无向图的连通性

- 无向联通图：任何两个结点之间存在一条路径
- 非连通图由两个或多个连通图组成
- Giant Component：最大连通域
- Isolated node：孤立结点



连通性举例

当一个图具有多个连通域，其邻接矩阵为形如对角矩阵的形式，因此非0元素均在方阵中，其他元素均为0



有向图的连通性

1. Strongly connected directed graph （强连通有向图）
   - 图中任意两个均可达到（A->B, B->A）

2. Weakly connected directed graph （弱连通有向图）
   - 忽略边的方向时，图中任意两个结点均可到达
3. Strongly connected components (SCCs，强连通域)
   - 不太理解
4. In-component：指向SCC
5. Out-component：由SCC指出



图机器学习常用工具

- PyG（PyTorch Geometric）：官方自己的库，和PyTorch类似
- GraphGym
- NetworkX
- DGL：李沐老师推荐的，适合进行学术研究
- 图数据可视化：AntV、Echarts、GraphXR
